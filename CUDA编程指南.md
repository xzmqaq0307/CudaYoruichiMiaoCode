## Chapter 0x01

#### 1. `GPU`计算的发展

##### 1.1 早期的`GPU`计算的缺陷

- 受限于图形`API`的编程模型：需要与`OpenGL`和`DirectX`交互
- 严格的资源限制：只能以颜色值和纹理单元等形式输入数据
- 计算结果写入内存的方式以及位置同样存在着严格限制

##### 1.2 图形处理架构和`CUDA`架构

- 图形处理架构：计算资源划分为顶点着色器和像素着色器
- `CUDA`架构：统一的着色流水线，使得执行通用计算的程序能对`ALU`进行排列

## Chapter 0x03

#### 1. 基本语法

##### 1.1 核函数

- `__global__`：该修饰符告诉编译器，函数应该在设备上运行而非主机上运行
- `kernel<<<>>>()`：将一些参数传递给运行时系统，这些参数并不是传递给设备代码的参数
  - 尖括号第一个参数指定的是并行线程块的数量指定的数量

##### 1.2 传递参数

- 设备执行任何有用的操作的时候，都需要分配内存，比如说返回计算值给主机
- `cudaMalloc()`：来进行`CUDA`运行时在设备上分配内存，第一个参数是指向地址的指针，第二个参数时分配内存的大小
  - 可以将分配的指针传递给在设备执行的函数
  - 可以将设备代码可以使用分配的指针进行内存读写操作
  - 可以将分配的指针传递在给主机执行的函数
  - 不能再主机代码中使用分配的指针读写内存
- `cudaMemcpy()`：拷贝由`cudaMalloc`分配的指针内容到主机实现的指针内存段上，才能够实现值读取。第一个参数是普通指针、第二个参数是设备指针、第三个参数是分配的内存大小、第四个参数是拷贝方向
  - `cudaMemcpyHostToDevice`、`cudaMemcpyDeviceToHost`、`cudaMemcpyDeviceToDevice`

##### 1.3 查询设备

- `cudaGetDeviceCount()`：查看`CUDA`设备的数量，第一个参数是`&count`即`int`型的地址
- `cudaGetDeviceProperties()`：查看`CUDA`设备的属性，第一个参数是`cudaDeviceProp`类型变量的地址，第二个参数是`int`变量，表示第几个`CUDA`设备

## Chapter 0x04

#### 1. 并行编程

##### 1.1 内置变量

- `blockIdx`：内置的二维线程块数组

